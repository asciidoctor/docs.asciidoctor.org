name: Site Indexer
on:
  schedule:
  - cron: '30 4 * * *'
  workflow_dispatch:
jobs:
  activate:
    runs-on: ubuntu-latest
    if: |
      github.repository == 'asciidoctor/docs.asciidoctor.org' &&
      (github.event_name == 'workflow_dispatch' || !endsWith(github.event.head_commit.message, ' [skip ci]'))
    steps:
    - run: echo ok go
  build:
    needs: activate
    runs-on: ubuntu-latest
    container: algolia/docsearch-scraper:v1.12.0
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    - name: Index
      env:
        APPLICATION_ID: ${{ secrets.ALGOLIA_APP_ID }}
        API_KEY: ${{ secrets.ALGOLIA_API_KEY }}
        CONFIG: ${{ github.workspace }}/docsearch/config.json
      run: |
        SITEMAP_URL=$(node -p "JSON.parse(require('fs').readFileSync('$CONFIG')).sitemap_urls[0].replace('.xml','-home.xml')")
        # the index is stale if the site has been published in the last 24 hours
        INDEX_STALE=$(curl -s $SITEMAP_URL | awk '/<lastmod>/{print gensub(/<lastmod>(.+)<\/lastmod>/,"\\1",1);exit}' | node -p 'Date.now() - +Date.parse(require("fs").readFileSync(0).toString().trim()) < 86400000')
        if [ "$INDEX_STALE" == "true" ]; then
          export HOME=/root
          export INDEX_NAME_TMP=$(node -p "JSON.parse(require('fs').readFileSync('$CONFIG')).index_name")_tmp-$GITHUB_RUN_ID
          cd $HOME
          pipenv run python -m src.index
        else
          echo 'SKIP: Index is already up to date.'
        fi
